{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4caf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa59465",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[~] Keywords     : dadan\n",
      "[~] Total Pages  : 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DETIKScraper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m pages \u001b[38;5;241m=\u001b[39m    \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[~] Total Pages  : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.detik.com/search/searchall\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 92\u001b[0m scrape \u001b[38;5;241m=\u001b[39m \u001b[43mDETIKScraper\u001b[49m(keywords, pages)\n\u001b[1;32m     93\u001b[0m response \u001b[38;5;241m=\u001b[39m scrape\u001b[38;5;241m.\u001b[39mfetch(base_url)\n\u001b[1;32m     94\u001b[0m articles \u001b[38;5;241m=\u001b[39m scrape\u001b[38;5;241m.\u001b[39mget_articles(response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DETIKScraper' is not defined"
     ]
    }
   ],
   "source": [
    "class Scraper:\n",
    "    def __init__(self, keywords, pages):\n",
    "        self.keywords = keywords\n",
    "        self.pages = pages\n",
    "\n",
    "    def fetch(self, base_url):\n",
    "        self.base_url = base_url\n",
    "\n",
    "        self.params = {\n",
    "            'query': self.keywords,\n",
    "            'sortby': 'time',\n",
    "            'page': 2\n",
    "        }\n",
    "\n",
    "        self.headers = {\n",
    "            'sec-ch-ua': '\"(Not(A:Brand\";v=\"8\", \"Chromium\";v=\"99\", \"Google Chrome\";v=\"99\"',\n",
    "            'sec-ch-ua-platform': \"Linux\",\n",
    "            'sec-fetch-site': 'same-origin',\n",
    "            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.35 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        self.response = requests.get(self.base_url, params=self.params, headers=self.headers)\n",
    "\n",
    "        return self.response\n",
    "\n",
    "    def get_articles(self, response):\n",
    "        article_lists = []\n",
    "\n",
    "        for page in range(1, int(self.pages)+1):\n",
    "            url = f\"{self.base_url}?query={self.keywords}&sortby=time&page={page}\"\n",
    "\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "            articles = soup.find_all(\"article\")\n",
    "\n",
    "            for article in articles:\n",
    "                title = article.find(\"h2\", {\"class\": \"title\"}).get_text()\n",
    "                category = article.find(\"span\", {\"class\": \"category\"}).get_text()\n",
    "                published_time = article.find(\"span\", {\"class\": \"date\"}).get_text().split(\",\")[1]\n",
    "                href = article.find(\"a\")[\"href\"]\n",
    "                descript = article.find(\"p\").get_text()\n",
    "                article_lists.append({\n",
    "                    \"title\": title, \n",
    "                    \"category\": category, \n",
    "                    \"published_time\": published_time, \n",
    "                    \"href\": href,\n",
    "                    \"descript\": descript})\n",
    "\n",
    "        self.articles = article_lists\n",
    "\n",
    "        try:\n",
    "            self.show_results()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            print()\n",
    "            print( \"[~] Scraping finished!\")\n",
    "            print(f\"[~] Total Articles: {len(self.articles)}\")\n",
    "\n",
    "        return self.articles\n",
    "\n",
    "    def save_to(self, file_format=\"csv\"):\n",
    "        '''  '''\n",
    "        time_scrape = datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "        df = pd.DataFrame(self.articles)\n",
    "\n",
    "        file_name = f\"result_{self.keywords}_{time_scrape}\"\n",
    "        if file_format == \"csv\":\n",
    "            file_name += \".csv\"\n",
    "            df.to_csv(file_name, index=False)\n",
    "            print(f\"[~] Result saved to '{file_name}'\")\n",
    "        elif file_format == \"excel\":\n",
    "            file_name += \".xlsx\"\n",
    "            df.to_excel(file_name, index=False)\n",
    "            print(f\"[~] Result saved to '{file_name}'\")\n",
    "\n",
    "    def show_results(self, row = 5):\n",
    "        df = pd.DataFrame(self.articles)\n",
    "        df.index += 1\n",
    "        if row:\n",
    "            print(df.head())\n",
    "        else:\n",
    "            print(df)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    keywords = input(\"[~] Keywords     : \")\n",
    "    pages =    input(\"[~] Total Pages  : \")\n",
    "    base_url = f\"https://www.detik.com/search/searchall\"\n",
    "\n",
    "    scrape = Scraper(keywords, pages)\n",
    "    response = scrape.fetch(base_url)\n",
    "    articles = scrape.get_articles(response)\n",
    "\n",
    "    try:\n",
    "        ask =             input(\"[~] Do you want save the results? [y/n]: \").lower()\n",
    "        if ask == 'y':\n",
    "            file_format = input(\"[~] Save to file format? [csv/excel]           : \").lower()\n",
    "            scrape.save_to(file_format=file_format)\n",
    "        elif ask == 'n':\n",
    "            scrape.show_results()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        print(\"[~] Program Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"result_teknik_05162022_223811.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24caadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"descript\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in data[\"href\"]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705c564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_scrape_detik]",
   "language": "python",
   "name": "conda-env-env_scrape_detik-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
